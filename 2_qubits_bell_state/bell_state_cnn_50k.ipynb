{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38053100-ae3e-42c2-9dc9-b0b4e0c8d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy as sp\n",
    "import csv\n",
    "import sympy\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from qiskit import Aer, execute, QuantumCircuit\n",
    "from qiskit.quantum_info import DensityMatrix, random_statevector\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc7826c-9cee-45d9-b41a-8eb537d5c36b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def create_circuit():\n",
    "    qc = QuantumCircuit(2)\n",
    "    qc.h(0)\n",
    "    qc.cx(0, 1)\n",
    "    return qc\n",
    "\n",
    "# Function to measure in different bases\n",
    "def measure_basis(qc, basis):\n",
    "    if basis == 'ZZ':\n",
    "        qc.measure_all()\n",
    "    elif basis == 'XX':\n",
    "        qc.h([0, 1])\n",
    "        qc.measure_all()\n",
    "    elif basis == 'YY':\n",
    "        qc.sdg([0, 1])\n",
    "        qc.h([0, 1])\n",
    "        qc.measure_all()\n",
    "    return qc\n",
    "\n",
    "# Function to simulate measurements\n",
    "def simulate_measurements(qc):\n",
    "    backend = Aer.get_backend('qasm_simulator')\n",
    "    result = execute(qc, backend, shots=1024).result()\n",
    "    counts = result.get_counts()\n",
    "    return counts\n",
    "\n",
    "# Function to collect measurement data\n",
    "def collect_data(statevector):\n",
    "    bases = ['ZZ', 'XX', 'YY']\n",
    "    data = []\n",
    "    for basis in bases:\n",
    "        qc = QuantumCircuit(2)\n",
    "        qc.initialize(statevector, [0, 1])\n",
    "        qc = create_circuit().compose(qc)\n",
    "        qc = measure_basis(qc, basis)\n",
    "        counts = simulate_measurements(qc)\n",
    "        data.append(counts)\n",
    "    return data\n",
    "\n",
    "# Convert measurement counts to probabilities\n",
    "def counts_to_probabilities(counts, num_qubits):\n",
    "    shots = sum(counts.values())\n",
    "    probabilities = {k: v / shots for k, v in counts.items()}\n",
    "    # Ensure all measurement outcomes are present\n",
    "    for i in range(2 ** num_qubits):\n",
    "        key = format(i, f'0{num_qubits}b')\n",
    "        if key not in probabilities:\n",
    "            probabilities[key] = 0.0\n",
    "    return probabilities\n",
    "\n",
    "# Preprocess the training data\n",
    "def preprocess_data(training_data, num_qubits):\n",
    "    processed_data = []\n",
    "    for sample in training_data:\n",
    "        sample_data = []\n",
    "        for counts in sample:\n",
    "            probabilities = counts_to_probabilities(counts, num_qubits)\n",
    "            sample_data.extend([probabilities[format(i, f'0{num_qubits}b')] for i in range(2 ** num_qubits)])\n",
    "        processed_data.append(sample_data)\n",
    "    return np.array(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35042f9-df79-4a84-b07c-1e930b41cf48",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: torch.Size([50000, 12])\n",
      "Shape of y_train: torch.Size([50000, 32])\n"
     ]
    }
   ],
   "source": [
    "# Import data from csv\n",
    "processed_training_data = np.loadtxt('processed_training_data_50000.csv', delimiter=',')\n",
    "training_labels = np.loadtxt('training_labels_50000.csv', delimiter=',')\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(processed_training_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(training_labels, dtype=torch.float32)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88936bad-2416-4b0a-84be-610cf8e211bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class FidelityLoss(nn.Module):\n",
    "    def forward(self, predicted, target):\n",
    "        real_pred = predicted[:, :16].view(-1, 4, 4)\n",
    "        imag_pred = predicted[:, 16:].view(-1, 4, 4)\n",
    "        pred_density_matrix = real_pred + 1j * imag_pred\n",
    "        real_target = target[:, :16].view(-1, 4, 4)\n",
    "        imag_target = target[:, 16:].view(-1, 4, 4)\n",
    "        target_density_matrix = real_target + 1j * imag_target\n",
    "        \n",
    "        # Compute the Frobenius norm between the predicted and target density matrices\n",
    "        diff = pred_density_matrix - target_density_matrix\n",
    "        frobenius_norm = torch.norm(diff, p='fro')\n",
    "        \n",
    "        loss = frobenius_norm.mean()\n",
    "        return loss\n",
    "\n",
    "class QuantumTomographyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantumTomographyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 12, 512)  # Adjust input dimension as needed\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 32)  # 16 real + 16 imaginary elements\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension for Conv1d\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = QuantumTomographyCNN()\n",
    "criterion = FidelityLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9771ae48-5b5f-4909-b41c-7796a951777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 1.5402\n",
      "Epoch [20/200], Loss: 1.2990\n",
      "Epoch [30/200], Loss: 1.1547\n",
      "Epoch [40/200], Loss: 1.0495\n",
      "Epoch [50/200], Loss: 0.9687\n",
      "Epoch [60/200], Loss: 0.7577\n",
      "Epoch [70/200], Loss: 0.7392\n",
      "Epoch [80/200], Loss: 0.7245\n",
      "Epoch [90/200], Loss: 0.7119\n",
      "Epoch [100/200], Loss: 0.7005\n",
      "Epoch [110/200], Loss: 0.6789\n",
      "Epoch [120/200], Loss: 0.6777\n",
      "Epoch [130/200], Loss: 0.6765\n",
      "Epoch [140/200], Loss: 0.6752\n",
      "Epoch [150/200], Loss: 0.6741\n",
      "Epoch [160/200], Loss: 0.6715\n",
      "Epoch [170/200], Loss: 0.6714\n",
      "Epoch [180/200], Loss: 0.6713\n",
      "Epoch [190/200], Loss: 0.6712\n",
      "Epoch [200/200], Loss: 0.6711\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoader for batching\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3442373a-2f07-4b91-9efc-7a351fb26ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to reconstruct quantum states from new data\n",
    "def reconstruct_density_matrix(measurement_data):\n",
    "    processed_data = preprocess_data([measurement_data], num_qubits)\n",
    "    input_tensor = torch.tensor(processed_data, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        predicted_elements = model(input_tensor).numpy()\n",
    "    real_part = predicted_elements[:, :16]\n",
    "    imag_part = predicted_elements[:, 16:]\n",
    "    combined_matrix = real_part + 1j * imag_part\n",
    "    return combined_matrix.reshape((4, 4))\n",
    "\n",
    "def check_fidelity(rho, sigma):\n",
    "    fidelity = (np.trace(sp.linalg.sqrtm(np.matmul(rho, sigma))))**2\n",
    "    return np.real(fidelity)\n",
    "\n",
    "def avrg_fidelity(n):\n",
    "    fids = []\n",
    "    for i in range(n):\n",
    "        statevector = random_statevector(2**num_qubits).data\n",
    "        new_data = collect_data(statevector)\n",
    "        reconstructed_density_matrix = reconstruct_density_matrix(new_data)\n",
    "        qc = QuantumCircuit(2)\n",
    "        qc.initialize(statevector, [0, 1])\n",
    "        qc = create_circuit().compose(qc)\n",
    "        state = execute(qc, Aer.get_backend('statevector_simulator')).result().get_statevector()\n",
    "        original_density_matrix = DensityMatrix(state).data\n",
    "        fid = check_fidelity(reconstructed_density_matrix, original_density_matrix)\n",
    "        fids.append(fid)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Finished with iteration number: {i}\")\n",
    "    print(f\"mean: {np.mean(fids)}\")\n",
    "    print(f\"std: {np.std(fids)}\")\n",
    "    return sum(fids) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ee2d976-3d2c-4ddb-8e30-bb5d08dcb921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with iteration number: 999\n",
      "mean: 0.9773527720634297\n",
      "std: 0.05938415987833717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9773527720634301"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_qubits = 2\n",
    "avrg_fidelity(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0733a0-f92b-4f31-97cc-6ebbaa87a671",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_21804\\4064902457.py:24: DeprecationWarning: The function ``qiskit.execute_function.execute()`` is deprecated as of qiskit 0.46.0. It will be removed in the Qiskit 1.0 release. This function combines ``transpile`` and ``backend.run``, which is covered by ``Sampler`` :mod:`~qiskit.primitives`. Alternatively, you can also run :func:`.transpile` followed by ``backend.run()``.\n",
      "  result = execute(qc, backend, shots=1024).result()\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_21804\\3761388123.py:8: DeprecationWarning: The function ``qiskit.execute_function.execute()`` is deprecated as of qiskit 0.46.0. It will be removed in the Qiskit 1.0 release. This function combines ``transpile`` and ``backend.run``, which is covered by ``Sampler`` :mod:`~qiskit.primitives`. Alternatively, you can also run :func:`.transpile` followed by ``backend.run()``.\n",
      "  state = execute(qc, Aer.get_backend('statevector_simulator')).result().get_statevector()\n"
     ]
    }
   ],
   "source": [
    "#Example of reconstructed state\n",
    "statevector = random_statevector(2**num_qubits).data\n",
    "new_data = collect_data(statevector)\n",
    "reconstructed_density_matrix = reconstruct_density_matrix(new_data)\n",
    "qc = QuantumCircuit(2)\n",
    "qc.initialize(statevector, [0, 1])\n",
    "qc = create_circuit().compose(qc)\n",
    "state = execute(qc, Aer.get_backend('statevector_simulator')).result().get_statevector()\n",
    "original_density_matrix = DensityMatrix(state).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfdcd92b-3db5-460e-906d-a43c1ef56c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0.55 & -0.174 + 0.147 i & -0.234 - 0.196 i & 0.207 + 0.184 i\\\\-0.174 - 0.147 i & 0.111 & 0.03 + 0.158 i & -0.038 - 0.125 i\\\\-0.234 + 0.196 i & 0.03 - 0.158 i & 0.202 & -0.178 - 0.021 i\\\\0.207 - 0.184 i & -0.038 + 0.125 i & -0.178 + 0.021 i & 0.137\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[            0.55, -0.174 + 0.147*I, -0.234 - 0.196*I,  0.207 + 0.184*I],\n",
       "[-0.174 - 0.147*I,            0.111,   0.03 + 0.158*I, -0.038 - 0.125*I],\n",
       "[-0.234 + 0.196*I,   0.03 - 0.158*I,            0.202, -0.178 - 0.021*I],\n",
       "[ 0.207 - 0.184*I, -0.038 + 0.125*I, -0.178 + 0.021*I,            0.137]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sympy.Matrix(reconstructed_density_matrix)\n",
    "M.applyfunc(lambda x: round(x, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b406a2bd-6b72-42c1-9077-ea1cac93295e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0.536 & -0.193 + 0.17 i & -0.253 - 0.183 i & 0.207 + 0.206 i\\\\-0.193 - 0.17 i & 0.123 & 0.033 + 0.146 i & -0.009 - 0.14 i\\\\-0.253 + 0.183 i & 0.033 - 0.146 i & 0.182 & -0.168 - 0.027 i\\\\0.207 - 0.206 i & -0.009 + 0.14 i & -0.168 + 0.027 i & 0.159\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[           0.536, -0.193 + 0.17*I, -0.253 - 0.183*I,  0.207 + 0.206*I],\n",
       "[ -0.193 - 0.17*I,           0.123,  0.033 + 0.146*I,  -0.009 - 0.14*I],\n",
       "[-0.253 + 0.183*I, 0.033 - 0.146*I,            0.182, -0.168 - 0.027*I],\n",
       "[ 0.207 - 0.206*I, -0.009 + 0.14*I, -0.168 + 0.027*I,            0.159]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sympy.Matrix(original_density_matrix)\n",
    "M.applyfunc(lambda x: round(x, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589863b5-0c34-46ce-beab-af0cc4a3264c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979965754533575"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_fidelity(original_density_matrix, reconstructed_density_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

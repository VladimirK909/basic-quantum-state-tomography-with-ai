{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38053100-ae3e-42c2-9dc9-b0b4e0c8d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy as sp\n",
    "import csv\n",
    "import sympy\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from qiskit import Aer, execute, QuantumCircuit\n",
    "from qiskit.quantum_info import DensityMatrix, random_statevector\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc7826c-9cee-45d9-b41a-8eb537d5c36b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def create_circuit():\n",
    "    qc = QuantumCircuit(3)\n",
    "    qc.h(0)\n",
    "    qc.cx(0, 1)\n",
    "    qc.cx(1, 2)\n",
    "    return qc\n",
    "\n",
    "# Function to measure in different bases\n",
    "def measure_basis(qc, basis):\n",
    "    if basis == 'ZZZ':\n",
    "        qc.measure_all()\n",
    "    elif basis == 'XXX':\n",
    "        qc.h([0, 1, 2])\n",
    "        qc.measure_all()\n",
    "    elif basis == 'YYY':\n",
    "        qc.sdg([0, 1, 2])\n",
    "        qc.h([0, 1, 2])\n",
    "        qc.measure_all()\n",
    "    return qc\n",
    "\n",
    "# Function to simulate measurements\n",
    "def simulate_measurements(qc):\n",
    "    backend = Aer.get_backend('qasm_simulator')\n",
    "    result = execute(qc, backend, shots=1024).result()\n",
    "    counts = result.get_counts()\n",
    "    return counts\n",
    "\n",
    "# Function to collect measurement data\n",
    "def collect_data(statevector):\n",
    "    bases = ['ZZZ', 'XXX', 'YYY']\n",
    "    data = []\n",
    "    for basis in bases:\n",
    "        qc = QuantumCircuit(3)\n",
    "        qc.initialize(statevector, [0, 1, 2])\n",
    "        qc = create_circuit().compose(qc)\n",
    "        qc = measure_basis(qc, basis)\n",
    "        counts = simulate_measurements(qc)\n",
    "        data.append(counts)\n",
    "    return data\n",
    "\n",
    "# Convert measurement counts to probabilities\n",
    "def counts_to_probabilities(counts, num_qubits):\n",
    "    shots = sum(counts.values())\n",
    "    probabilities = {k: v / shots for k, v in counts.items()}\n",
    "    # Ensure all measurement outcomes are present\n",
    "    for i in range(2 ** num_qubits):\n",
    "        key = format(i, f'0{num_qubits}b')\n",
    "        if key not in probabilities:\n",
    "            probabilities[key] = 0.0\n",
    "    return probabilities\n",
    "\n",
    "# Preprocess the training data\n",
    "def preprocess_data(training_data, num_qubits):\n",
    "    processed_data = []\n",
    "    for sample in training_data:\n",
    "        sample_data = []\n",
    "        for counts in sample:\n",
    "            probabilities = counts_to_probabilities(counts, num_qubits)\n",
    "            sample_data.extend([probabilities[format(i, f'0{num_qubits}b')] for i in range(2 ** num_qubits)])\n",
    "        processed_data.append(sample_data)\n",
    "    return np.array(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a35042f9-df79-4a84-b07c-1e930b41cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from csv\n",
    "processed_training_data = np.loadtxt('3q-processed_training_data_20000.csv', delimiter=',')\n",
    "training_labels = np.loadtxt('3q-training_labels_20000.csv', delimiter=',')\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(processed_training_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(training_labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88936bad-2416-4b0a-84be-610cf8e211bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN and Loss\n",
    "class FidelityLoss(nn.Module):\n",
    "    def forward(self, predicted, target):\n",
    "        real_pred = predicted[:, :64].view(-1, 8, 8)\n",
    "        imag_pred = predicted[:, 64:].view(-1, 8, 8)\n",
    "        pred_density_matrix = real_pred + 1j * imag_pred\n",
    "        real_target = target[:, :64].view(-1, 8, 8)\n",
    "        imag_target = target[:, 64:].view(-1, 8, 8)\n",
    "        target_density_matrix = real_target + 1j * imag_target\n",
    "        \n",
    "        # Compute the Frobenius norm between the predicted and target density matrices\n",
    "        diff = pred_density_matrix - target_density_matrix\n",
    "        frobenius_norm = torch.norm(diff, p='fro')\n",
    "        \n",
    "        loss = frobenius_norm.mean()\n",
    "        return loss\n",
    "\n",
    "class QuantumTomographyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantumTomographyNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(24, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 128)  # Adjusted output size for 3-qubit density matrix (64 real + 64 imaginary)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca9028d9-5d9f-494e-b7ee-254566a53bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 4.9513\n",
      "Epoch [20/200], Loss: 4.9145\n",
      "Epoch [30/200], Loss: 4.8961\n",
      "Epoch [40/200], Loss: 4.8962\n",
      "Epoch [50/200], Loss: 4.8980\n",
      "Epoch [60/200], Loss: 4.7550\n",
      "Epoch [70/200], Loss: 4.7372\n",
      "Epoch [80/200], Loss: 4.7218\n",
      "Epoch [90/200], Loss: 4.7165\n",
      "Epoch [100/200], Loss: 4.7111\n",
      "Epoch [110/200], Loss: 4.6969\n",
      "Epoch [120/200], Loss: 4.6942\n",
      "Epoch [130/200], Loss: 4.6911\n",
      "Epoch [140/200], Loss: 4.6911\n",
      "Epoch [150/200], Loss: 4.6910\n",
      "Epoch [160/200], Loss: 4.6889\n",
      "Epoch [170/200], Loss: 4.6884\n",
      "Epoch [180/200], Loss: 4.6898\n",
      "Epoch [190/200], Loss: 4.6885\n",
      "Epoch [200/200], Loss: 4.6878\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = QuantumTomographyNN()\n",
    "criterion = FidelityLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3442373a-2f07-4b91-9efc-7a351fb26ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_density_matrix(measurement_data):\n",
    "    processed_data = preprocess_data([measurement_data], num_qubits)\n",
    "    input_tensor = torch.tensor(processed_data, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        predicted_elements = model(input_tensor).numpy()\n",
    "    real_part = predicted_elements[:, :64]\n",
    "    imag_part = predicted_elements[:, 64:]\n",
    "    combined_matrix = real_part + 1j * imag_part\n",
    "    return combined_matrix.reshape((8, 8))\n",
    "\n",
    "def check_fidelity(rho, sigma):\n",
    "    fidelity = (np.trace(sp.linalg.sqrtm(np.matmul(rho, sigma))))**2\n",
    "    return np.real(fidelity)\n",
    "\n",
    "def avrg_fidelity(n):\n",
    "    fids = []\n",
    "    for i in range(n):\n",
    "        statevector = random_statevector(2**num_qubits).data\n",
    "        new_data = collect_data(statevector)\n",
    "        reconstructed_density_matrix = reconstruct_density_matrix(new_data)\n",
    "        qc = QuantumCircuit(3)\n",
    "        qc.initialize(statevector, [0, 1, 2])\n",
    "        qc = create_circuit().compose(qc)\n",
    "        state = execute(qc, Aer.get_backend('statevector_simulator')).result().get_statevector()\n",
    "        original_density_matrix = DensityMatrix(state).data\n",
    "        fid = check_fidelity(reconstructed_density_matrix, original_density_matrix)\n",
    "        print(fid)\n",
    "        fids.append(fid)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Finished with iteration number: {i}\")\n",
    "    print(f\"mean: {np.mean(fids)}\")\n",
    "    print(f\"std: {np.std(fids)}\")\n",
    "    return sum(fids) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee2d976-3d2c-4ddb-8e30-bb5d08dcb921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with iteration number: 999\n",
      "mean: 0.31261507128094285\n",
      "std: 0.07008680846490746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3126150712809428"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_qubits = 3\n",
    "avrg_fidelity(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0c0733a0-f92b-4f31-97cc-6ebbaa87a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of reconstructed state\n",
    "statevector = random_statevector(2**num_qubits).data\n",
    "new_data = collect_data(statevector)\n",
    "reconstructed_density_matrix = reconstruct_density_matrix(new_data)\n",
    "qc = QuantumCircuit(2)\n",
    "qc.initialize(statevector, [0, 1])\n",
    "qc = create_circuit().compose(qc)\n",
    "state = execute(qc, Aer.get_backend('statevector_simulator')).result().get_statevector()\n",
    "original_density_matrix = DensityMatrix(state).data\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bfdcd92b-3db5-460e-906d-a43c1ef56c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0.24 & 0.006 - 0.068 i & 0.121 - 0.208 i & 0.133 - 0.21 i\\\\0.006 + 0.068 i & 0.083 & 0.212 - 0.037 i & 0.033 - 0.003 i\\\\0.121 + 0.208 i & 0.212 + 0.037 i & 0.395 & 0.261 - 0.07 i\\\\0.133 + 0.21 i & 0.033 + 0.003 i & 0.261 + 0.07 i & 0.282\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[           0.24, 0.006 - 0.068*I, 0.121 - 0.208*I,  0.133 - 0.21*I],\n",
       "[0.006 + 0.068*I,           0.083, 0.212 - 0.037*I, 0.033 - 0.003*I],\n",
       "[0.121 + 0.208*I, 0.212 + 0.037*I,           0.395,  0.261 - 0.07*I],\n",
       "[ 0.133 + 0.21*I, 0.033 + 0.003*I,  0.261 + 0.07*I,           0.282]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sympy.Matrix(reconstructed_density_matrix)\n",
    "M.applyfunc(lambda x: round(x, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b406a2bd-6b72-42c1-9077-ea1cac93295e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0.237 & 0.014 - 0.187 i & -0.008 - 0.274 i & 0.096 - 0.248 i\\\\0.014 + 0.187 i & 0.149 & 0.216 - 0.023 i & 0.201 + 0.06 i\\\\-0.008 + 0.274 i & 0.216 + 0.023 i & 0.317 & 0.283 + 0.118 i\\\\0.096 + 0.248 i & 0.201 - 0.06 i & 0.283 - 0.118 i & 0.297\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[           0.237, 0.014 - 0.187*I, -0.008 - 0.274*I, 0.096 - 0.248*I],\n",
       "[ 0.014 + 0.187*I,           0.149,  0.216 - 0.023*I,  0.201 + 0.06*I],\n",
       "[-0.008 + 0.274*I, 0.216 + 0.023*I,            0.317, 0.283 + 0.118*I],\n",
       "[ 0.096 + 0.248*I,  0.201 - 0.06*I,  0.283 - 0.118*I,           0.297]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sympy.Matrix(original_density_matrix)\n",
    "M.applyfunc(lambda x: round(x, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "589863b5-0c34-46ce-beab-af0cc4a3264c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7833189200989189"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_fidelity(original_density_matrix, reconstructed_density_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
